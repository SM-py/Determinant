# Determinant
Категорирует статьи по тексту и заголовку из списка категорий Википедии при помощи взаимодействия нейросетей и алгоритмов

При созданиии одного из моих предыдщих проектов (сайт со статьями) возникла проблема с категоризацией статей. Было очень много статей, и ни у одной из них не было определена категория. Для обучения собственной нейросети требовалась размеченная выборка, а использовать уже готовые решения не представлялось возможным из-за того что большая часть из них не подходили под специфику работы (тогда было начало 2021 года и NLP модели только начинали своё активное развитие). Для решения данной задачи был создан Determinant - алгоритм, который основывается на базе данных Википедии и применении некоторых языковых моделей обработки натурального языка.

Суть алгоритма проста - на вход подаётся заголовок и текст статьи. Слова проходят морфологический анализ и приводятся к инфинитиву для того чтобы форма слова не имела влияния на результат, и затем в них ищутся биграммы. Потом среди биграмм ищутся биграммы которые могут быть важными для определения смысла статьи на основе частей речи слов внутри биграмм. После того как имеющие смысл словосочетания и отдельные слова найдены, они сортируются по количеству повторений в тексте. Затем ключевые фразы проверяются на мовпадение с категориями с Википедии, затем оцениваются на сходство нейросетью. После этого ключевые слова с самым большим весом отправляются на определение категории. Там начинается поиск общих категорий между словами, и категория с наибольшим количеством пересечений возвращается алгоритмом.

Данный алгоритм настроен на определённую нишу (геодезия, строительство, обустройство дома, ландшафтный дизайн, растения), и поэтому если тема статьи выходит за рамки этой ниши она может быть поределена неправильно. При этом если заменить отмеченные переменные, то алгоритм может работать и с другими категориями. Алгоритм не был окончательно доработан из-за пропавшей в нём необходимости, но даже в недоработанном состоянии готов выполнять свою функцию. Тем не менее у него есть проблемы с оптимизацией и он может не справляться со случаями, когда тем в статье очень много, а так же у него возникают сложности с многозанчными словами.

Код не до конца задокументирован, но я постарался описать функции которые можно использовать за пределами класса. Алгоритм во многом уже не актуален, но это не новейшая разработка а публикация приватного проекта 2021 года.

Для использования нужно установить библиотеки из requirments.txt

Файл для запуска - determinant.py

Так же нужно в папке проекта создать папку geowac и в нее распаковать содержимок архива:

https://drive.google.com/file/d/1r83gtBktdXBgdfxlsevUZbOsubpnlRlN/view?usp=drive_link


В папку проекта нужно догрузить файл ruwordnet.db: 

https://drive.google.com/file/d/1RKCAN-6hO4Oqaswh2bMZaU4iMR7CyxHL/view?usp=drive_link

Файлы слишком большие, поэтому я не смог их загрузить на Гитхаб

